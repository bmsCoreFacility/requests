---
title: "Drug compound optimization"
author: "Christopher Hughes"
format: html
---

## Details

This document describes processing the output from Skyline related to optimization of drug compounds.

## Setting up the environment

These are packages you will need for this notebook. For exact versions used, please refer to the session info at the bottom of this notebook.

```{r}
#| message: false
#| warning: false
##########################################################################################
library('tidyverse')
library('ggpmisc')
#library('pastecs')
```

I want to set a base directory that we can use for our analysis.

```{r}
##########################################################################################
baseRepository = 'E:/requests/1169/241211_1169_qtrap'
```

## Data processing

The raw data have already been processed and integrated in Skyline. From here, we will use these data for downstream analyses. The first thing to do is to extract the standard data and create the standard curves.

```{r}
##########################################################################################
##read in the data from Skyline
standards = rep(c(25,12.5,6.25,3.125,1.5625,0.78125,0),each = 3) #in ug/mL
skyRaw = read_csv(paste(baseRepository,'/skyline/moleculeTransitionResults.csv',sep=''),show_col_types = FALSE) %>%
  dplyr::filter(`Product Mz` == 121.1 | `Product Mz` == 60.1) %>%
  dplyr::filter(grepl('standard',`Replicate Name`)) %>%
  dplyr::select(`Replicate Name`, `Precursor Mz`, `Product Mz`, Area, Background) %>%
  dplyr::rename(sampleName = `Replicate Name`,
                parentMass = `Precursor Mz`,
                fragmentMass = `Product Mz`,
                signal = 'Area',
                noise = 'Background') %>%
  dplyr::mutate(concentration = rep(standards,6)) %>%
  dplyr::mutate(sampleType = ifelse(parentMass == 292.0, 'experimentalSample', 
                                    ifelse(grepl('blank',sampleName),'blank','ilis')),
                sampleSet = ifelse(grepl('A[0-9]',sampleName),'setA',
                                   ifelse(grepl('B[0-9]',sampleName),'setB',
                                          ifelse(grepl('C[0-9]',sampleName),'setC','blank')))) %>%
  dplyr::mutate(sampleReplicate = sub('.*_rep(.*)','\\1',sampleName)) %>%
  dplyr::mutate(sampleNumber = sub('standard_[ABC](.*)_rep.*','\\1',sampleName)) %>%
  dplyr::filter(!grepl('E', sampleNumber))


##reshape the data
skyWide = skyRaw %>%
  tidyr::pivot_wider(id_cols = c('sampleName','sampleSet','sampleNumber','sampleReplicate'), names_from = 'sampleType', values_from = 'signal') %>%
  dplyr::mutate(relativeToIlis = experimentalSample/ilis)


#save the data
saveRDS(skyWide, paste(baseRepository,'/dataProcessing/dataset_processedStandardData.rds',sep=''))
write.table(skyWide, paste(baseRepository,'/dataProcessing/dataset_processedStandardData.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)
```

Plot the different standard curves.

```{r}
##########################################################################################
##read in the processed data
standards = rep(c(0.78125,1.5625,3.125,6.25,12.5,25),each = 3) #in ug/mL
stdData = readRDS(paste(baseRepository,'/dataProcessing/dataset_processedStandardData.rds',sep='')) %>%
  dplyr::select(sampleNumber, sampleSet, sampleReplicate, experimentalSample, relativeToIlis) %>%
  dplyr::mutate(sampleConcentration = rep(standards,3))


##setA
dat = dplyr::filter(stdData, grepl('setA',sampleSet))
ggplot(dat, aes(sampleConcentration, experimentalSample)) +
  stat_poly_line(formula = y ~ x) +
  stat_poly_eq(formula = y ~ x, use_label(c("eq", "R2")),rr.digits = 6) +
  #stat_poly_line(formula = y ~ poly(x,2)) +
  #stat_poly_eq(formula = y ~ poly(x,2), use_label(c("eq", "R2")),rr.digits = 6) +
  geom_point(shape = 21, stroke = 1, size = 2) + 
  #stat_smooth(method = "loess", formula = y~x, linewidth = 1) +
  #stat_smooth(method = "lm", formula = y ~ x + I(x^2), size = 1) +
  labs(x = 'Standard Concentration (ug/mL)', y = 'Area', title = 'Set A Linearity') +
  theme_classic()
ggsave(paste(baseRepository,'/dataProcessing/point_standardCurve_setA.png',sep=''),
       width = 6, height = 6)


##setB
dat = dplyr::filter(stdData, grepl('setB',sampleSet))
ggplot(dat, aes(sampleConcentration, experimentalSample)) +
  stat_poly_line(formula = y ~ x) +
  stat_poly_eq(formula = y ~ x, use_label(c("eq", "R2")),rr.digits = 6) +
  #stat_poly_line(formula = y ~ poly(x,2)) +
  #stat_poly_eq(formula = y ~ poly(x,2), use_label(c("eq", "R2")),rr.digits = 6) +
  geom_point(shape = 21, stroke = 1, size = 2) + 
  labs(x = 'Standard Concentration (ug/mL)', y = 'Area', title = 'Set B Linearity') +
  theme_classic()
ggsave(paste(baseRepository,'/dataProcessing/point_standardCurve_setB.png',sep=''),
       width = 6, height = 6)


##setB
dat = dplyr::filter(stdData, grepl('setB',sampleSet) & sampleNumber != 4) #sample number 4 was messed up so I excluded it for now
ggplot(dat, aes(sampleConcentration, experimentalSample)) +
  stat_poly_line(formula = y ~ x) +
  stat_poly_eq(formula = y ~ x, use_label(c("eq", "R2")),rr.digits = 6) +
  #stat_poly_line(formula = y ~ poly(x,2)) +
  #stat_poly_eq(formula = y ~ poly(x,2), use_label(c("eq", "R2")),rr.digits = 6) +
  geom_point(shape = 21, stroke = 1, size = 2) + 
  labs(x = 'Standard Concentration (ug/mL)', y = 'Area', title = 'Set B Linearity') +
  theme_classic()
ggsave(paste(baseRepository,'/dataProcessing/point_standardCurve_setB_sample4Excluded.png',sep=''),
       width = 6, height = 6)

##setC
dat = dplyr::filter(stdData, grepl('setC',sampleSet))
ggplot(dat, aes(sampleConcentration, experimentalSample)) +
  stat_poly_line(formula = y ~ x) +
  stat_poly_eq(formula = y ~ x, use_label(c("eq", "R2")),rr.digits = 6) +
  #stat_poly_line(formula = y ~ poly(x,2)) +
  #stat_poly_eq(formula = y ~ poly(x,2), use_label(c("eq", "R2")),rr.digits = 6) +
  geom_point(shape = 21, stroke = 1, linewidth = 2) + 
  labs(x = 'Standard Concentration (ug/mL)', y = 'Area', title = 'Set C Linearity') +
  theme_classic()
ggsave(paste(baseRepository,'/dataProcessing/point_standardCurve_setC.png',sep=''),
       width = 6, height = 6)
```

Calculate the matrix effect (ME), recovery (RE), and process efficiency (PE).

```{r}
##########################################################################################
##read in the processed data
standards = rep(c(0.78125,1.5625,3.125,6.25,12.5,25),each = 3) #in ug/mL
meData = readRDS(paste(baseRepository,'/dataProcessing/dataset_processedStandardData.rds',sep='')) %>%
  dplyr::select(sampleNumber, sampleSet, sampleReplicate, sample) %>%
  tidyr::pivot_wider(id_cols = c('sampleNumber','sampleReplicate'), names_from = 'sampleSet', values_from = 'sample') %>%
  dplyr::mutate(ME = (setC / setA)*100,
                RE = (setB / setC)*100,
                PE = (ME * RE)/100) %>%
  dplyr::mutate(standardConcentration = standards) %>%
  dplyr::group_by(sampleNumber, standardConcentration) %>%
  dplyr::summarise(setA = mean(setA), setB = mean(setB), setC = mean(setC), ME = mean(ME), RE = mean(RE), PE = mean(PE))
meData

#
write.table(meData, paste(baseRepository,'/dataProcessing/dataset_efficiencyData.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)
```

Calculate the original concentrations for the standards based on the standard curve data.

```{r}
##########################################################################################
##get the standard data
#equation from corrected B curve y = 1.02e7 + 2.63e7x - 5.83e6x2
xValue = 7.72e5
bValue =  2.96e6 #taken from setB standard curve
standards = rep(c(0.78125,1.5625,3.125,6.25,12.5,25),each = 3) #in ug/mL

stdData = readRDS(paste(baseRepository,'/dataProcessing/dataset_processedStandardData.rds',sep='')) %>%
  dplyr::select(sampleNumber, sampleSet, sampleReplicate, experimentalSample) %>%
  dplyr::mutate(sampleConcentration = rep(standards,3)) %>%
  dplyr::filter(sampleSet == 'setB') %>%
  dplyr::mutate(calcConcentration = (experimentalSample - bValue)/xValue) %>%
  dplyr::mutate(acc = (calcConcentration/sampleConcentration)*100) %>%
  dplyr::group_by(sampleNumber, sampleSet, sampleConcentration) %>%
  dplyr::summarise(mean_acc = mean(acc, na.rm = TRUE), sd_acc = sd(acc, na.rm = TRUE)) %>%
  dplyr::mutate(cv = (sd_acc/mean_acc)*100)

#
write.table(stdData, paste(baseRepository,'/dataProcessing/dataset_accuracyData.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)
```

Plot the SSC samples to look at performance as the run batch was moving along.

```{r}
##########################################################################################
##read in the processed data
sscData = read_csv(paste(baseRepository,'/skyline/moleculeTransitionResults.csv',sep=''),show_col_types = FALSE) %>% 
  dplyr::filter(`Product Mz` == 121.1 | `Product Mz` == 60.1) %>%
  dplyr::filter(grepl('ssc',`Replicate Name`)) %>%
  dplyr::select(`Replicate Name`, `Product Mz`, Area, Background) %>%
  dplyr::rename(sampleName = `Replicate Name`,
                fragmentMass = `Product Mz`,
                signal = 'Area',
                noise = 'Background') %>%
  dplyr::mutate(sampleType = ifelse(fragmentMass == 121.1, 'sample', 
                                    ifelse(grepl('blank',sampleName),'blank','ilis'))) %>%
  dplyr::mutate(sampleReplicate = sub('.*_rep(.*)','\\1',sampleName)) %>%
  dplyr::mutate(sampleSet = paste('ssc',sampleReplicate,sep='')) %>%
  tidyr::pivot_wider(id_cols = c('sampleName','sampleSet','sampleReplicate'), names_from = 'sampleType', values_from = 'signal') %>%
  dplyr::filter(sample > 100000)

#
write.table(sscData, paste(baseRepository,'/dataProcessing/dataset_systemSuitabilityStandardData.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)

##plot
dat = sscData
ggplot(dat, aes(sampleSet, log10(sample))) +
  geom_point(shape = 21, stroke = 1, size = 2) + 
  labs(x = 'SSC Run Number', y = 'Methoctramine Area', title = 'System Suitability Standard Performance') +
  scale_y_continuous(limits = c(0,10), breaks = seq(0,10,2)) +
  theme_classic() +
  theme(axis.text.x = element_blank())
ggsave(paste(baseRepository,'/dataProcessing/point_sscTimecourse.png',sep=''),
       width = 6, height = 6)
```

Some of the SSC samples are messed up. Not sure if it is a machine issue, or if it is the method itself. There doesn't seem to be any consistency to it. 

Prepare the QC data to look at signal drop off across days. 

```{r}
##########################################################################################
##read in the processed data
standards = rep(c(0,1.5625,6.25,25),each = 3) #in ug/mL

##
qcData = read_csv(paste(baseRepository,'/skyline/moleculeTransitionResults.csv',sep=''),show_col_types = FALSE) %>% 
  dplyr::filter(`Product Mz` == 121.1 | `Product Mz` == 60.1) %>%
  dplyr::filter(grepl('qc',`Replicate Name`)) %>%
  dplyr::select(`Replicate Name`, `Product Mz`, Area, Background) %>%
  dplyr::rename(sampleName = `Replicate Name`,
                fragmentMass = `Product Mz`,
                signal = 'Area',
                noise = 'Background') %>%
  dplyr::mutate(preparedConcentration = rep(standards,6)) %>%
  dplyr::mutate(sampleType = ifelse(fragmentMass == 121.1, 'sample', 
                                    ifelse(grepl('blank',sampleName),'blank','ilis')),
                sampleSet = ifelse(grepl('E',sampleName),'empty',
                                   ifelse(grepl('H',sampleName),'high',
                                          ifelse(grepl('L',sampleName),'low','medium')))) %>%
  dplyr::mutate(sampleReplicate = sub('.*_rep(.*)','\\1',sampleName)) %>%
  dplyr::mutate(sampleNumber = sub('sample_qc_(.*)_rep.*','\\1',sampleName)) %>%
  tidyr::pivot_wider(id_cols = c('sampleName','sampleSet','sampleNumber','sampleReplicate','preparedConcentration'), names_from = 'sampleType', values_from = 'signal')
  
#
write.table(qcData, paste(baseRepository,'/dataProcessing/dataset_qcRawData.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)

#calculate intraday variability
intraDay = qcData %>%
  dplyr::select(sampleNumber, sample) %>%
  dplyr::group_by(sampleNumber) %>%
  dplyr::summarise(mean_signal = mean(sample, na.rm = TRUE), sd_signal = sd(sample, na.rm = TRUE)) %>%
  dplyr::mutate(cv = (sd_signal/mean_signal)*100)

#
write.table(intraDay, paste(baseRepository,'/dataProcessing/dataset_qcIntraday.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE) 

#calculate interday variability
interDay = intraDay %>%
  dplyr::mutate(sampleName = sub('(.*)[0-9]','\\1',sampleNumber)) %>%
  dplyr::select(sampleName, mean_signal) %>%
  dplyr::rename(signal = 'mean_signal') %>%
  dplyr::group_by(sampleName) %>%
  dplyr::summarise(mean_signal = mean(signal, na.rm = TRUE), sd_signal = sd(signal, na.rm = TRUE)) %>%
  dplyr::mutate(cv = (sd_signal/mean_signal)*100) 
  
#
write.table(interDay, paste(baseRepository,'/dataProcessing/dataset_qcInterday.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)
```

Calculate the CV of the CSF measurements. 

```{r}
##########################################################################################
##read in the processed data
standards = rep(c(0,6.25),each = 3) #in ug/mL

##
csfData = read_csv(paste(baseRepository,'/skyline/moleculeTransitionResults.csv',sep=''),show_col_types = FALSE) %>% 
  dplyr::filter(`Product Mz` == 121.1 | `Product Mz` == 60.1) %>%
  dplyr::filter(grepl('csf',`Replicate Name`)) %>%
  dplyr::select(`Replicate Name`, `Product Mz`, Area, Background) %>%
  dplyr::rename(sampleName = `Replicate Name`,
                fragmentMass = `Product Mz`,
                signal = 'Area',
                noise = 'Background') %>%
  #dplyr::mutate(preparedConcentration = rep(standards,6)) %>%
  dplyr::mutate(sampleType = ifelse(fragmentMass == 121.1, 'sample', 
                                    ifelse(grepl('blank',sampleName),'blank','ilis')),
                sampleSet = ifelse(grepl('E',sampleName),'empty','spike')) %>%
  dplyr::mutate(sampleReplicate = sub('.*_rep(.*)','\\1',sampleName)) %>%
  dplyr::mutate(sampleNumber = sub('sample_csf_(.*)_rep.*','\\1',sampleName)) %>%
  tidyr::pivot_wider(id_cols = c('sampleName','sampleSet','sampleNumber','sampleReplicate'), names_from = 'sampleType', values_from = 'signal') %>%
  dplyr::mutate(analysisDay = ifelse(sampleReplicate < 4, 'D1', 
                                     ifelse(sampleReplicate > 3 & sampleReplicate < 7, 'D2', 'D3')))
  
#
write.table(csfData, paste(baseRepository,'/dataProcessing/dataset_csfRawData.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)

#calculate intraday variability
intraDay = csfData %>%
  dplyr::select(sampleNumber, analysisDay, sample) %>%
  dplyr::group_by(sampleNumber, analysisDay) %>%
  dplyr::summarise(mean_signal = mean(sample, na.rm = TRUE), sd_signal = sd(sample, na.rm = TRUE)) %>%
  dplyr::mutate(cv = (sd_signal/mean_signal)*100)

#
write.table(intraDay, paste(baseRepository,'/dataProcessing/dataset_csfIntraday.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE) 

#calculate interday variability
interDay = intraDay %>%
  dplyr::rename(signal = 'mean_signal') %>%
  dplyr::group_by(sampleNumber) %>%
  dplyr::summarise(mean_signal = mean(signal, na.rm = TRUE), sd_signal = sd(signal, na.rm = TRUE)) %>%
  dplyr::mutate(cv = (sd_signal/mean_signal)*100) 
  
#
write.table(interDay, paste(baseRepository,'/dataProcessing/dataset_csfInterday.tsv',sep=''),
            sep = '\t', quote = FALSE, row.names = FALSE)
```
















